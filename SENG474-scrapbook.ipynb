{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once deleted, variables cannot be recovered. Proceed (y/[n])? y\n"
     ]
    }
   ],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///C:/Users/Yichun/Documents/UVic/2021%20Spring/SENG474/project/codes/mibexx_gym\n",
      "Requirement already satisfied: gym in c:\\users\\yichun\\appdata\\roaming\\python\\python36\\site-packages (from mibexx-gym-minesweeper==0.0.3) (0.18.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\yichun\\appdata\\roaming\\python\\python36\\site-packages (from mibexx-gym-minesweeper==0.0.3) (1.19.5)\n",
      "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in c:\\users\\yichun\\appdata\\roaming\\python\\python36\\site-packages (from gym->mibexx-gym-minesweeper==0.0.3) (1.6.0)\n",
      "Requirement already satisfied: scipy in c:\\programdata\\anaconda3\\lib\\site-packages (from gym->mibexx-gym-minesweeper==0.0.3) (1.2.1)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym->mibexx-gym-minesweeper==0.0.3) (1.5.0)\n",
      "Requirement already satisfied: Pillow<=7.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from gym->mibexx-gym-minesweeper==0.0.3) (5.4.1)\n",
      "Requirement already satisfied: future in c:\\programdata\\anaconda3\\lib\\site-packages (from pyglet<=1.5.0,>=1.4.0->gym->mibexx-gym-minesweeper==0.0.3) (0.18.2)\n",
      "Installing collected packages: mibexx-gym-minesweeper\n",
      "  Found existing installation: mibexx-gym-minesweeper 0.0.3\n",
      "    Uninstalling mibexx-gym-minesweeper-0.0.3:\n",
      "      Successfully uninstalled mibexx-gym-minesweeper-0.0.3\n",
      "  Running setup.py develop for mibexx-gym-minesweeper\n",
      "Successfully installed mibexx-gym-minesweeper\n"
     ]
    }
   ],
   "source": [
    "#!python -m pip uninstall pyqt5 --yes\n",
    "#!pip3 install pyqt5==5.12.0 --user\n",
    "\n",
    "#!pip install mibexx-gym-minesweeper --user\n",
    "!pip install -e ./mibexx_gym/ \n",
    "\n",
    "#!pip install keras --user\n",
    "#!pip install tensorflow --user\n",
    "\n",
    "#!python -m pip uninstall keras-rl2 --yes\n",
    "#!pip install keras-rl2 --user\n",
    "\n",
    "#!pip list\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space:  (9, 9)\n",
      "Action space:  [9 9]\n",
      "Reward: 0 Done: False\n",
      "Reward: -1 Done: False\n",
      "[[-1  1  0  0  0  0  0  0  0]\n",
      " [ 1  2  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "env = gym.make('mibexx_gym_minesweeper:mibexx-gym-minesweeper-v0')\n",
    "\n",
    "env.reset()\n",
    "done = False\n",
    "\n",
    "# TEST\n",
    "\n",
    "print(\"Observation space: \", env.observation_space.shape)\n",
    "print(\"Action space: \", env.action_space.nvec)\n",
    "\n",
    "\n",
    "state, reward, done, _ = env.step((0, 0))\n",
    "print(f\"Reward: {reward} Done: {done}\")\n",
    "state, reward, done, _ = env.step((0, 0))\n",
    "print(f\"Reward: {reward} Done: {done}\")\n",
    "\n",
    "env.render()\n",
    "\n",
    "env.reset()\n",
    "done = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0]]\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 0  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]] 0 False {} [5 4]\n",
      "\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 0  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]]\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 0  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]] 0 False {} [7 6]\n",
      "\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 0  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]]\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 0  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]] 0 False {} [6 5]\n",
      "\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 0  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]]\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]] 0 False {} [3 0]\n",
      "\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]]\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]] -1 False {} [0 0]\n",
      "\n",
      "[[-1 -1 -1  1  0  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]]\n",
      "[[-1 -1 -1  1 -2  1 -1  1  0]\n",
      " [ 1  1 -1  1  1  1 -1  1  0]\n",
      " [ 0  1 -1 -1 -1 -1 -1  2  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [ 0  1  1  1 -1  1  0  0  0]\n",
      " [ 0  0  0  1 -1  2  0  0  0]\n",
      " [ 0  2  1  1 -1  1  0  0  0]\n",
      " [ 1  1 -1 -1 -1  1  1  2  0]\n",
      " [-1 -1 -1 -1 -1 -1 -1  1  0]] -10 True {} [0 4]\n",
      "\n",
      "Finished after 6 timesteps\n"
     ]
    }
   ],
   "source": [
    "#np.random.seed(123)\n",
    "#env.seed(123)\n",
    "\n",
    "#env.action_space.nvec\n",
    "#env.action_space.sample()\n",
    "\n",
    "nb_actions = env.action_space.nvec[0] * env.action_space.nvec[1]\n",
    "\n",
    "observation = env.reset()\n",
    "for t in range(100):\n",
    "        env.render()\n",
    "        action = env.action_space.sample()\n",
    "        (observation, reward, done, info) = env.step(action)\n",
    "        print (observation, reward, done, info, action)\n",
    "        print()\n",
    "        if done:\n",
    "            print(\"Finished after {} timesteps\".format(t+1))\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import keras\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "from rl.agents.dqn import DQNAgent \n",
    "from rl.policy import EpsGreedyQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "#from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_model():\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=(1,) + env.observation_space.shape))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(50))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dense(81))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_14 (Flatten)         (None, 81)                0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 50)                4100      \n",
      "_________________________________________________________________\n",
      "activation_39 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 81)                4131      \n",
      "=================================================================\n",
      "Total params: 13,331\n",
      "Trainable params: 13,331\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = nn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for 1000 steps ...\n",
      "Interval 1 (0 steps performed)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.int64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-e75428c72c6e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1e-4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0menv\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\rl\\core.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, env, nb_steps, action_repetition, callbacks, verbose, visualize, nb_max_start_steps, start_step_policy, log_interval, nb_max_episode_steps)\u001b[0m\n\u001b[0;32m    175\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction_repetition\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_action_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                     \u001b[0mobservation\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    178\u001b[0m                     \u001b[0mobservation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\yichun\\documents\\uvic\\2021 spring\\seng474\\project\\codes\\mibexx_gym\\mibexx_gym_minesweeper\\envs\\minesweeper_env.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mdone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m         \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m         \u001b[0mfield_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.int64' object is not iterable"
     ]
    }
   ],
   "source": [
    "policy = EpsGreedyQPolicy()\n",
    "memory = SequentialMemory(limit=50000, window_length=1)\n",
    "dqn = DQNAgent(\n",
    "               model=model,\n",
    "               nb_actions = 81, \n",
    "               memory=memory, \n",
    "               nb_steps_warmup=100, \n",
    "               target_model_update=1e-3, \n",
    "               policy=policy,\n",
    "               enable_double_dqn=True,\n",
    "              )\n",
    "dqn.compile(Adam(lr=1e-4), metrics=['mae'])\n",
    " \n",
    "history = dqn.fit(env, nb_steps = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
